{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Arzw8ESVRvw0"
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1738833512154,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "AxMp5R_-Ro5g",
    "outputId": "8dec75fe-fafa-4cbc-8cee-a90e932faf00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Current Version: 3.8.0 Tensorflow Current Version: 2.18.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "print(\"Keras Current Version:\", keras.__version__, \"Tensorflow Current Version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1738833516125,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "pdlULouSRshx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import ReLU, LeakyReLU, PReLU\n",
    "from keras_tuner import RandomSearch\n",
    "\n",
    "\n",
    "random.seed(46)\n",
    "np.random.seed(46)\n",
    "tf.random.set_seed(46)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oNCpG5nSDD8"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1738833516151,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "8z6vZCS7SBEf"
   },
   "outputs": [],
   "source": [
    "def grab_col_names(dataframe, cat_th=10, car_th=20):\n",
    "    \"\"\"\n",
    "    Identifies categorical, numerical, and high-cardinality categorical variables in the dataset.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe : pd.DataFrame\n",
    "        The dataframe to analyze.\n",
    "    cat_th : int, optional (default=10)\n",
    "        Threshold for a numeric column to be considered categorical.\n",
    "    car_th : int, optional (default=20)\n",
    "        Threshold for a categorical column to be considered high-cardinality.\n",
    "\n",
    "    Returns:\n",
    "    cat_cols : list\n",
    "        List of categorical variables.\n",
    "    num_cols : list\n",
    "        List of numerical variables.\n",
    "    cat_but_car : list\n",
    "        List of categorical variables with high cardinality.\n",
    "    \"\"\"\n",
    "    # Identify categorical columns (object type)\n",
    "    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n",
    "\n",
    "    # Identify numerical columns that should be considered categorical\n",
    "    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and dataframe[col].dtypes != \"O\"]\n",
    "\n",
    "    # Identify high-cardinality categorical columns\n",
    "    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and dataframe[col].dtypes == \"O\"]\n",
    "\n",
    "    # Combine categorical and numerical-but-categorical columns\n",
    "    cat_cols = cat_cols + num_but_cat\n",
    "    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n",
    "\n",
    "    # Identify numerical columns\n",
    "    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n",
    "    num_cols = [col for col in num_cols if col not in num_but_cat]\n",
    "\n",
    "    return cat_cols, num_cols, cat_but_car\n",
    "\n",
    "def prepare_datasets(X_train, X_val, y_train, y_val, batch_size=None):\n",
    "    \"\"\"\n",
    "    Converts training and validation datasets into TensorFlow Dataset format.\n",
    "\n",
    "    Parameters:\n",
    "    X_train, X_val : np.array or pd.DataFrame\n",
    "        Feature matrices for training and validation.\n",
    "    y_train, y_val : np.array or pd.Series\n",
    "        Labels for training and validation.\n",
    "    batch_size : int, optional\n",
    "        Batch size (default: entire dataset as one batch).\n",
    "\n",
    "    Returns:\n",
    "    train_dataset : tf.data.Dataset\n",
    "        Training dataset.\n",
    "    val_dataset : tf.data.Dataset\n",
    "        Validation dataset.\n",
    "    \"\"\"\n",
    "    if batch_size is None:\n",
    "        batch_size = len(X_train)\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train)).batch(batch_size)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size)\n",
    "\n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def plot_training_history(history, train_loss='loss', train_metric='accuracy', val_loss='val_loss', val_metric='val_accuracy'):\n",
    "    \"\"\"\n",
    "    Plots training and validation loss and metrics over epochs.\n",
    "\n",
    "    Parameters:\n",
    "    history : keras.callbacks.History\n",
    "        Model training history.\n",
    "    train_loss : str, optional\n",
    "        Name of the training loss metric.\n",
    "    train_metric : str, optional\n",
    "        Name of the training accuracy metric.\n",
    "    val_loss : str, optional\n",
    "        Name of the validation loss metric.\n",
    "    val_metric : str, optional\n",
    "        Name of the validation accuracy metric.\n",
    "    \"\"\"\n",
    "    # Plot training and validation loss\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history[train_loss], label='Training Loss')\n",
    "    plt.plot(history.history[val_loss], label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot training and validation accuracy\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(history.history[train_metric], label=f\"Training {train_metric}\")\n",
    "    plt.plot(history.history[val_metric], label=f\"Validation {val_metric}\")\n",
    "    plt.title(f'Training and Validation {train_metric} Over Epochs')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(f'{train_metric}')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def get_best_epoch_details(history, metric=\"val_loss\", mode=min):\n",
    "    \"\"\"\n",
    "    Finds the best epoch based on a given metric and returns its details.\n",
    "\n",
    "    Parameters:\n",
    "    history : keras.callbacks.History\n",
    "        Model training history.\n",
    "    metric : str, optional\n",
    "        Metric to evaluate (default: validation loss).\n",
    "    mode : function, optional\n",
    "        Function to determine the best epoch (min/max).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame\n",
    "        Dataframe containing the best epoch's metric values.\n",
    "    \"\"\"\n",
    "    metric_values = history.history[metric]\n",
    "    best_epoch_index = metric_values.index(mode(metric_values))\n",
    "    best_epoch = best_epoch_index + 1\n",
    "\n",
    "    # Extract all metric values for the best epoch\n",
    "    metrics = []\n",
    "    values = []\n",
    "    for key, value in history.history.items():\n",
    "        metrics.append(key)\n",
    "        values.append(value[best_epoch_index])\n",
    "\n",
    "    df = pd.DataFrame({'Metric': metrics, 'Value': values})\n",
    "    df['Value'] = df['Value'].map('{:.4f}'.format)\n",
    "\n",
    "    # Append the best epoch number\n",
    "    best_epoch_data = pd.DataFrame({'Metric': ['best_epoch'], 'Value': [str(best_epoch)]})\n",
    "    df = pd.concat([df, best_epoch_data], ignore_index=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def print_hyperparameters(hyperparameters):\n",
    "    \"\"\"\n",
    "    Displays model hyperparameters in a formatted table.\n",
    "\n",
    "    Parameters:\n",
    "    hyperparameters : dict\n",
    "        Dictionary containing model hyperparameters.\n",
    "    \"\"\"\n",
    "    hp_df = pd.DataFrame(list(hyperparameters.items()), columns=['Hyperparameter', 'Value'])\n",
    "    print(hp_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_kON9jtwSKM6"
   },
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1738833516163,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "CDIpS9AHSJvp"
   },
   "outputs": [],
   "source": [
    "def dataproprocessing(dataframe):\n",
    "    cat_cols, num_cols, cat_but_car = grab_col_names(dataframe)\n",
    "\n",
    "    dataframe[\"TotalCharges\"] = pd.to_numeric(dataframe[\"TotalCharges\"], errors='coerce')\n",
    "\n",
    "    dataframe[\"TotalCharges\"] = dataframe[\"TotalCharges\"].fillna(dataframe[\"TotalCharges\"].median())\n",
    "\n",
    "    # feature engineering\n",
    "    dataframe.loc[(dataframe[\"tenure\"] >= 0) & (dataframe[\"tenure\"] <= 12), \"NEW_TENURE_YEAR\"] = \"0-1 Year\"\n",
    "    dataframe.loc[(dataframe[\"tenure\"] > 12) & (dataframe[\"tenure\"] <= 24), \"NEW_TENURE_YEAR\"] = \"1-2 Year\"\n",
    "    dataframe.loc[(dataframe[\"tenure\"] > 24) & (dataframe[\"tenure\"] <= 36), \"NEW_TENURE_YEAR\"] = \"2-3 Year\"\n",
    "    dataframe.loc[(dataframe[\"tenure\"] > 36) & (dataframe[\"tenure\"] <= 48), \"NEW_TENURE_YEAR\"] = \"3-4 Year\"\n",
    "    dataframe.loc[(dataframe[\"tenure\"] > 48) & (dataframe[\"tenure\"] <= 60), \"NEW_TENURE_YEAR\"] = \"4-5 Year\"\n",
    "    dataframe.loc[(dataframe[\"tenure\"] > 60) & (dataframe[\"tenure\"] <= 72), \"NEW_TENURE_YEAR\"] = \"5-6 Year\"\n",
    "\n",
    "    dataframe[\"NEW_Engaged\"] = dataframe[\"Contract\"].apply(lambda x: 1 if x in [\"One year\", \"Two year\"] else 0)\n",
    "\n",
    "    dataframe[\"NEW_noProt\"] = dataframe.apply(lambda x: 1 if (x[\"OnlineBackup\"] != \"Yes\") or (x[\"DeviceProtection\"] != \"Yes\") or (\n",
    "                x[\"TechSupport\"] != \"Yes\") else 0, axis=1)\n",
    "\n",
    "    dataframe[\"NEW_Young_Not_Engaged\"] = dataframe.apply(lambda x: 1 if (x[\"NEW_Engaged\"] == 0) and (x[\"SeniorCitizen\"] == 0) else 0,\n",
    "                                          axis=1)\n",
    "\n",
    "    dataframe['NEW_TotalServices'] = (dataframe[['PhoneService', 'InternetService', 'OnlineSecurity',\n",
    "                                  'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
    "                                  'StreamingTV', 'StreamingMovies']] == 'Yes').sum(axis=1)\n",
    "\n",
    "    dataframe[\"NEW_FLAG_ANY_STREAMING\"] = dataframe.apply(\n",
    "        lambda x: 1 if (x[\"StreamingTV\"] == \"Yes\") or (x[\"StreamingMovies\"] == \"Yes\") else 0, axis=1)\n",
    "\n",
    "    dataframe[\"NEW_FLAG_AutoPayment\"] = dataframe[\"PaymentMethod\"].apply(\n",
    "        lambda x: 1 if x in [\"Bank transfer (automatic)\", \"Credit card (automatic)\"] else 0)\n",
    "\n",
    "    dataframe[\"NEW_AVG_Charges\"] = dataframe[\"TotalCharges\"] / (dataframe[\"tenure\"] + 1)\n",
    "\n",
    "    dataframe[\"NEW_Increase\"] = dataframe[\"NEW_AVG_Charges\"] / dataframe[\"MonthlyCharges\"]\n",
    "\n",
    "    dataframe[\"NEW_AVG_Service_Fee\"] = dataframe[\"MonthlyCharges\"] / (dataframe['NEW_TotalServices'] + 1)\n",
    "\n",
    "    cat_cols, num_cols, cat_but_car = grab_col_names(dataframe)\n",
    "\n",
    "    cat_cols.remove(\"Churn\")\n",
    "\n",
    "    dataframe = pd.get_dummies(dataframe, columns=cat_cols, drop_first=True, dtype=int)\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    dataframe[num_cols] = scaler.fit_transform(dataframe[num_cols])\n",
    "\n",
    "    dump(scaler, 'scaler.joblib')\n",
    "\n",
    "    dataframe.columns = [col.replace(' ', '_').upper() for col in dataframe.columns]\n",
    "\n",
    "    y = dataframe[\"CHURN\"]\n",
    "    X = dataframe.drop([\"CHURN\", \"CUSTOMERID\"], axis=1)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hlnPdu3SRQ8"
   },
   "source": [
    "# Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1738833516198,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "u0ThJZ6hSPYC"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 178
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1738833516237,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "Z_Q0-zLOSTdm",
    "outputId": "5b7f6d14-c545-4c63-fafc-40fd4fd7921d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Churn\n",
       "0   73.46301\n",
       "1   26.53699\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Churn\"].value_counts() * 100 / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1738833516621,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "ky_MGZHgSU2U"
   },
   "outputs": [],
   "source": [
    "X, y = dataproprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 243
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1738833516673,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "fHXNX_SaSXe0",
    "outputId": "0f614e8b-2891-4e61-e6d2-346ac733411a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TENURE</th>\n",
       "      <th>MONTHLYCHARGES</th>\n",
       "      <th>TOTALCHARGES</th>\n",
       "      <th>NEW_AVG_CHARGES</th>\n",
       "      <th>NEW_INCREASE</th>\n",
       "      <th>NEW_AVG_SERVICE_FEE</th>\n",
       "      <th>GENDER_MALE</th>\n",
       "      <th>PARTNER_YES</th>\n",
       "      <th>DEPENDENTS_YES</th>\n",
       "      <th>PHONESERVICE_YES</th>\n",
       "      <th>MULTIPLELINES_NO_PHONE_SERVICE</th>\n",
       "      <th>MULTIPLELINES_YES</th>\n",
       "      <th>INTERNETSERVICE_FIBER_OPTIC</th>\n",
       "      <th>INTERNETSERVICE_NO</th>\n",
       "      <th>ONLINESECURITY_NO_INTERNET_SERVICE</th>\n",
       "      <th>ONLINESECURITY_YES</th>\n",
       "      <th>ONLINEBACKUP_NO_INTERNET_SERVICE</th>\n",
       "      <th>ONLINEBACKUP_YES</th>\n",
       "      <th>DEVICEPROTECTION_NO_INTERNET_SERVICE</th>\n",
       "      <th>DEVICEPROTECTION_YES</th>\n",
       "      <th>TECHSUPPORT_NO_INTERNET_SERVICE</th>\n",
       "      <th>TECHSUPPORT_YES</th>\n",
       "      <th>STREAMINGTV_NO_INTERNET_SERVICE</th>\n",
       "      <th>STREAMINGTV_YES</th>\n",
       "      <th>STREAMINGMOVIES_NO_INTERNET_SERVICE</th>\n",
       "      <th>STREAMINGMOVIES_YES</th>\n",
       "      <th>CONTRACT_ONE_YEAR</th>\n",
       "      <th>CONTRACT_TWO_YEAR</th>\n",
       "      <th>PAPERLESSBILLING_YES</th>\n",
       "      <th>PAYMENTMETHOD_CREDIT_CARD_(AUTOMATIC)</th>\n",
       "      <th>PAYMENTMETHOD_ELECTRONIC_CHECK</th>\n",
       "      <th>PAYMENTMETHOD_MAILED_CHECK</th>\n",
       "      <th>NEW_TENURE_YEAR_1-2_YEAR</th>\n",
       "      <th>NEW_TENURE_YEAR_2-3_YEAR</th>\n",
       "      <th>NEW_TENURE_YEAR_3-4_YEAR</th>\n",
       "      <th>NEW_TENURE_YEAR_4-5_YEAR</th>\n",
       "      <th>NEW_TENURE_YEAR_5-6_YEAR</th>\n",
       "      <th>SENIORCITIZEN_1</th>\n",
       "      <th>NEW_ENGAGED_1</th>\n",
       "      <th>NEW_NOPROT_1</th>\n",
       "      <th>NEW_YOUNG_NOT_ENGAGED_1</th>\n",
       "      <th>NEW_TOTALSERVICES_1</th>\n",
       "      <th>NEW_TOTALSERVICES_2</th>\n",
       "      <th>NEW_TOTALSERVICES_3</th>\n",
       "      <th>NEW_TOTALSERVICES_4</th>\n",
       "      <th>NEW_TOTALSERVICES_5</th>\n",
       "      <th>NEW_TOTALSERVICES_6</th>\n",
       "      <th>NEW_TOTALSERVICES_7</th>\n",
       "      <th>NEW_FLAG_ANY_STREAMING_1</th>\n",
       "      <th>NEW_FLAG_AUTOPAYMENT_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.11542</td>\n",
       "      <td>0.00128</td>\n",
       "      <td>0.00414</td>\n",
       "      <td>0.00041</td>\n",
       "      <td>0.20710</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.47222</td>\n",
       "      <td>0.38507</td>\n",
       "      <td>0.21587</td>\n",
       "      <td>0.03227</td>\n",
       "      <td>0.00677</td>\n",
       "      <td>0.18441</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02778</td>\n",
       "      <td>0.35423</td>\n",
       "      <td>0.01031</td>\n",
       "      <td>0.01935</td>\n",
       "      <td>0.00282</td>\n",
       "      <td>0.15883</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.62500</td>\n",
       "      <td>0.23930</td>\n",
       "      <td>0.21024</td>\n",
       "      <td>0.02221</td>\n",
       "      <td>0.00674</td>\n",
       "      <td>0.06353</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02778</td>\n",
       "      <td>0.52189</td>\n",
       "      <td>0.01533</td>\n",
       "      <td>0.02980</td>\n",
       "      <td>0.00346</td>\n",
       "      <td>0.88119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TENURE  MONTHLYCHARGES  TOTALCHARGES  NEW_AVG_CHARGES  NEW_INCREASE  \\\n",
       "0 0.01389         0.11542       0.00128          0.00414       0.00041   \n",
       "1 0.47222         0.38507       0.21587          0.03227       0.00677   \n",
       "2 0.02778         0.35423       0.01031          0.01935       0.00282   \n",
       "3 0.62500         0.23930       0.21024          0.02221       0.00674   \n",
       "4 0.02778         0.52189       0.01533          0.02980       0.00346   \n",
       "\n",
       "   NEW_AVG_SERVICE_FEE  GENDER_MALE  PARTNER_YES  DEPENDENTS_YES  \\\n",
       "0              0.20710            0            1               0   \n",
       "1              0.18441            1            0               0   \n",
       "2              0.15883            1            0               0   \n",
       "3              0.06353            1            0               0   \n",
       "4              0.88119            0            0               0   \n",
       "\n",
       "   PHONESERVICE_YES  MULTIPLELINES_NO_PHONE_SERVICE  MULTIPLELINES_YES  \\\n",
       "0                 0                               1                  0   \n",
       "1                 1                               0                  0   \n",
       "2                 1                               0                  0   \n",
       "3                 0                               1                  0   \n",
       "4                 1                               0                  0   \n",
       "\n",
       "   INTERNETSERVICE_FIBER_OPTIC  INTERNETSERVICE_NO  \\\n",
       "0                            0                   0   \n",
       "1                            0                   0   \n",
       "2                            0                   0   \n",
       "3                            0                   0   \n",
       "4                            1                   0   \n",
       "\n",
       "   ONLINESECURITY_NO_INTERNET_SERVICE  ONLINESECURITY_YES  \\\n",
       "0                                   0                   0   \n",
       "1                                   0                   1   \n",
       "2                                   0                   1   \n",
       "3                                   0                   1   \n",
       "4                                   0                   0   \n",
       "\n",
       "   ONLINEBACKUP_NO_INTERNET_SERVICE  ONLINEBACKUP_YES  \\\n",
       "0                                 0                 1   \n",
       "1                                 0                 0   \n",
       "2                                 0                 1   \n",
       "3                                 0                 0   \n",
       "4                                 0                 0   \n",
       "\n",
       "   DEVICEPROTECTION_NO_INTERNET_SERVICE  DEVICEPROTECTION_YES  \\\n",
       "0                                     0                     0   \n",
       "1                                     0                     1   \n",
       "2                                     0                     0   \n",
       "3                                     0                     1   \n",
       "4                                     0                     0   \n",
       "\n",
       "   TECHSUPPORT_NO_INTERNET_SERVICE  TECHSUPPORT_YES  \\\n",
       "0                                0                0   \n",
       "1                                0                0   \n",
       "2                                0                0   \n",
       "3                                0                1   \n",
       "4                                0                0   \n",
       "\n",
       "   STREAMINGTV_NO_INTERNET_SERVICE  STREAMINGTV_YES  \\\n",
       "0                                0                0   \n",
       "1                                0                0   \n",
       "2                                0                0   \n",
       "3                                0                0   \n",
       "4                                0                0   \n",
       "\n",
       "   STREAMINGMOVIES_NO_INTERNET_SERVICE  STREAMINGMOVIES_YES  \\\n",
       "0                                    0                    0   \n",
       "1                                    0                    0   \n",
       "2                                    0                    0   \n",
       "3                                    0                    0   \n",
       "4                                    0                    0   \n",
       "\n",
       "   CONTRACT_ONE_YEAR  CONTRACT_TWO_YEAR  PAPERLESSBILLING_YES  \\\n",
       "0                  0                  0                     1   \n",
       "1                  1                  0                     0   \n",
       "2                  0                  0                     1   \n",
       "3                  1                  0                     0   \n",
       "4                  0                  0                     1   \n",
       "\n",
       "   PAYMENTMETHOD_CREDIT_CARD_(AUTOMATIC)  PAYMENTMETHOD_ELECTRONIC_CHECK  \\\n",
       "0                                      0                               1   \n",
       "1                                      0                               0   \n",
       "2                                      0                               0   \n",
       "3                                      0                               0   \n",
       "4                                      0                               1   \n",
       "\n",
       "   PAYMENTMETHOD_MAILED_CHECK  NEW_TENURE_YEAR_1-2_YEAR  \\\n",
       "0                           0                         0   \n",
       "1                           1                         0   \n",
       "2                           1                         0   \n",
       "3                           0                         0   \n",
       "4                           0                         0   \n",
       "\n",
       "   NEW_TENURE_YEAR_2-3_YEAR  NEW_TENURE_YEAR_3-4_YEAR  \\\n",
       "0                         0                         0   \n",
       "1                         1                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         1   \n",
       "4                         0                         0   \n",
       "\n",
       "   NEW_TENURE_YEAR_4-5_YEAR  NEW_TENURE_YEAR_5-6_YEAR  SENIORCITIZEN_1  \\\n",
       "0                         0                         0                0   \n",
       "1                         0                         0                0   \n",
       "2                         0                         0                0   \n",
       "3                         0                         0                0   \n",
       "4                         0                         0                0   \n",
       "\n",
       "   NEW_ENGAGED_1  NEW_NOPROT_1  NEW_YOUNG_NOT_ENGAGED_1  NEW_TOTALSERVICES_1  \\\n",
       "0              0             1                        1                    1   \n",
       "1              1             1                        0                    0   \n",
       "2              0             1                        1                    0   \n",
       "3              1             1                        0                    0   \n",
       "4              0             1                        1                    1   \n",
       "\n",
       "   NEW_TOTALSERVICES_2  NEW_TOTALSERVICES_3  NEW_TOTALSERVICES_4  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    1                    0   \n",
       "2                    0                    1                    0   \n",
       "3                    0                    1                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   NEW_TOTALSERVICES_5  NEW_TOTALSERVICES_6  NEW_TOTALSERVICES_7  \\\n",
       "0                    0                    0                    0   \n",
       "1                    0                    0                    0   \n",
       "2                    0                    0                    0   \n",
       "3                    0                    0                    0   \n",
       "4                    0                    0                    0   \n",
       "\n",
       "   NEW_FLAG_ANY_STREAMING_1  NEW_FLAG_AUTOPAYMENT_1  \n",
       "0                         0                       0  \n",
       "1                         0                       0  \n",
       "2                         0                       0  \n",
       "3                         0                       1  \n",
       "4                         0                       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1738833516681,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "y10CluwJSaDp",
    "outputId": "91a8a3b8-f197-4f06-80cc-749f65045838"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-fVI050SdyJ"
   },
   "source": [
    "# Train Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1738833516730,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "36Tth38BSbqt"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "train_ds, val_ds = prepare_datasets(X_train, X_val, y_train, y_val, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SM4KOwySSjCp"
   },
   "source": [
    "# Base Model with Binary Log Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 58624,
     "status": "ok",
     "timestamp": 1738833575355,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "1deAHMLMShNU",
    "outputId": "57e88f0c-e275-4495-8e84-4e5e6d92dfc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.5781 - auc: 0.5995 - loss: 0.8961 - precision: 0.3324 - recall: 0.5478 - val_accuracy: 0.7743 - val_auc: 0.8271 - val_loss: 0.5062 - val_precision: 0.6455 - val_recall: 0.3271\n",
      "Epoch 2/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7369 - auc: 0.7555 - loss: 0.5829 - precision: 0.5106 - recall: 0.5446 - val_accuracy: 0.7977 - val_auc: 0.8448 - val_loss: 0.4606 - val_precision: 0.6594 - val_recall: 0.4879\n",
      "Epoch 3/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7596 - auc: 0.7900 - loss: 0.5268 - precision: 0.5541 - recall: 0.5029 - val_accuracy: 0.8027 - val_auc: 0.8490 - val_loss: 0.4531 - val_precision: 0.6444 - val_recall: 0.5684\n",
      "Epoch 4/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7806 - auc: 0.8068 - loss: 0.5065 - precision: 0.6175 - recall: 0.5131 - val_accuracy: 0.8055 - val_auc: 0.8494 - val_loss: 0.4505 - val_precision: 0.6656 - val_recall: 0.5335\n",
      "Epoch 5/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7792 - auc: 0.8140 - loss: 0.4953 - precision: 0.6178 - recall: 0.4859 - val_accuracy: 0.7984 - val_auc: 0.8479 - val_loss: 0.4515 - val_precision: 0.6440 - val_recall: 0.5335\n",
      "Epoch 6/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7903 - auc: 0.8252 - loss: 0.4729 - precision: 0.6313 - recall: 0.4931 - val_accuracy: 0.8070 - val_auc: 0.8528 - val_loss: 0.4426 - val_precision: 0.6656 - val_recall: 0.5442\n",
      "Epoch 7/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7886 - auc: 0.8131 - loss: 0.4823 - precision: 0.6143 - recall: 0.4933 - val_accuracy: 0.8070 - val_auc: 0.8533 - val_loss: 0.4420 - val_precision: 0.6593 - val_recall: 0.5603\n",
      "Epoch 8/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7859 - auc: 0.8366 - loss: 0.4637 - precision: 0.6351 - recall: 0.5044 - val_accuracy: 0.8013 - val_auc: 0.8528 - val_loss: 0.4402 - val_precision: 0.6643 - val_recall: 0.5040\n",
      "Epoch 9/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7828 - auc: 0.8289 - loss: 0.4702 - precision: 0.6294 - recall: 0.4746 - val_accuracy: 0.8055 - val_auc: 0.8535 - val_loss: 0.4370 - val_precision: 0.6701 - val_recall: 0.5228\n",
      "Epoch 10/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8061 - auc: 0.8474 - loss: 0.4475 - precision: 0.6869 - recall: 0.5268 - val_accuracy: 0.8062 - val_auc: 0.8491 - val_loss: 0.4414 - val_precision: 0.6894 - val_recall: 0.4879\n",
      "Epoch 11/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7986 - auc: 0.8401 - loss: 0.4571 - precision: 0.6789 - recall: 0.5013 - val_accuracy: 0.8062 - val_auc: 0.8506 - val_loss: 0.4385 - val_precision: 0.6678 - val_recall: 0.5335\n",
      "Epoch 12/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7928 - auc: 0.8381 - loss: 0.4468 - precision: 0.6279 - recall: 0.4878 - val_accuracy: 0.8070 - val_auc: 0.8513 - val_loss: 0.4353 - val_precision: 0.6603 - val_recall: 0.5576\n",
      "Epoch 13/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7947 - auc: 0.8393 - loss: 0.4538 - precision: 0.6644 - recall: 0.4943 - val_accuracy: 0.8119 - val_auc: 0.8535 - val_loss: 0.4315 - val_precision: 0.6753 - val_recall: 0.5576\n",
      "Epoch 14/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8039 - auc: 0.8436 - loss: 0.4414 - precision: 0.6561 - recall: 0.5175 - val_accuracy: 0.8098 - val_auc: 0.8534 - val_loss: 0.4334 - val_precision: 0.6513 - val_recall: 0.6059\n",
      "Epoch 15/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8023 - auc: 0.8370 - loss: 0.4478 - precision: 0.6595 - recall: 0.5187 - val_accuracy: 0.8084 - val_auc: 0.8539 - val_loss: 0.4295 - val_precision: 0.6700 - val_recall: 0.5442\n",
      "Epoch 16/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8062 - auc: 0.8414 - loss: 0.4471 - precision: 0.6844 - recall: 0.5201 - val_accuracy: 0.8126 - val_auc: 0.8533 - val_loss: 0.4292 - val_precision: 0.6799 - val_recall: 0.5523\n",
      "Epoch 17/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7934 - auc: 0.8356 - loss: 0.4486 - precision: 0.6401 - recall: 0.5030 - val_accuracy: 0.8062 - val_auc: 0.8540 - val_loss: 0.4279 - val_precision: 0.6761 - val_recall: 0.5147\n",
      "Epoch 18/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7930 - auc: 0.8482 - loss: 0.4385 - precision: 0.6667 - recall: 0.4890 - val_accuracy: 0.8055 - val_auc: 0.8532 - val_loss: 0.4290 - val_precision: 0.6514 - val_recall: 0.5710\n",
      "Epoch 19/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8036 - auc: 0.8435 - loss: 0.4313 - precision: 0.6516 - recall: 0.4926 - val_accuracy: 0.8098 - val_auc: 0.8526 - val_loss: 0.4272 - val_precision: 0.6677 - val_recall: 0.5603\n",
      "Epoch 20/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7967 - auc: 0.8433 - loss: 0.4383 - precision: 0.6609 - recall: 0.4979 - val_accuracy: 0.8126 - val_auc: 0.8538 - val_loss: 0.4267 - val_precision: 0.6775 - val_recall: 0.5576\n",
      "Epoch 21/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7950 - auc: 0.8405 - loss: 0.4397 - precision: 0.6471 - recall: 0.5008 - val_accuracy: 0.8062 - val_auc: 0.8534 - val_loss: 0.4265 - val_precision: 0.6462 - val_recall: 0.5925\n",
      "Epoch 22/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7982 - auc: 0.8461 - loss: 0.4361 - precision: 0.6731 - recall: 0.5111 - val_accuracy: 0.8105 - val_auc: 0.8538 - val_loss: 0.4246 - val_precision: 0.6767 - val_recall: 0.5442\n",
      "Epoch 23/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7955 - auc: 0.8363 - loss: 0.4454 - precision: 0.6626 - recall: 0.4800 - val_accuracy: 0.8091 - val_auc: 0.8533 - val_loss: 0.4259 - val_precision: 0.6656 - val_recall: 0.5603\n",
      "Epoch 24/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7988 - auc: 0.8485 - loss: 0.4396 - precision: 0.6830 - recall: 0.5197 - val_accuracy: 0.8155 - val_auc: 0.8524 - val_loss: 0.4258 - val_precision: 0.7070 - val_recall: 0.5174\n",
      "Epoch 25/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8080 - auc: 0.8560 - loss: 0.4169 - precision: 0.6706 - recall: 0.5268 - val_accuracy: 0.8062 - val_auc: 0.8522 - val_loss: 0.4251 - val_precision: 0.6786 - val_recall: 0.5094\n",
      "Epoch 26/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8066 - auc: 0.8523 - loss: 0.4274 - precision: 0.6833 - recall: 0.5199 - val_accuracy: 0.8062 - val_auc: 0.8527 - val_loss: 0.4250 - val_precision: 0.6534 - val_recall: 0.5710\n",
      "Epoch 27/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7980 - auc: 0.8506 - loss: 0.4245 - precision: 0.6492 - recall: 0.5154 - val_accuracy: 0.8077 - val_auc: 0.8531 - val_loss: 0.4243 - val_precision: 0.6509 - val_recall: 0.5898\n",
      "Epoch 28/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7972 - auc: 0.8494 - loss: 0.4219 - precision: 0.6357 - recall: 0.5054 - val_accuracy: 0.8091 - val_auc: 0.8530 - val_loss: 0.4233 - val_precision: 0.6844 - val_recall: 0.5174\n",
      "Epoch 29/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8057 - auc: 0.8531 - loss: 0.4238 - precision: 0.6767 - recall: 0.5161 - val_accuracy: 0.8098 - val_auc: 0.8541 - val_loss: 0.4222 - val_precision: 0.6744 - val_recall: 0.5442\n",
      "Epoch 30/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7940 - auc: 0.8369 - loss: 0.4407 - precision: 0.6465 - recall: 0.4813 - val_accuracy: 0.8070 - val_auc: 0.8535 - val_loss: 0.4229 - val_precision: 0.6712 - val_recall: 0.5308\n",
      "Epoch 31/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8083 - auc: 0.8525 - loss: 0.4254 - precision: 0.6841 - recall: 0.5192 - val_accuracy: 0.8084 - val_auc: 0.8536 - val_loss: 0.4215 - val_precision: 0.6722 - val_recall: 0.5389\n",
      "Epoch 32/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7959 - auc: 0.8374 - loss: 0.4428 - precision: 0.6653 - recall: 0.5080 - val_accuracy: 0.8162 - val_auc: 0.8524 - val_loss: 0.4224 - val_precision: 0.6770 - val_recall: 0.5845\n",
      "Epoch 33/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8028 - auc: 0.8523 - loss: 0.4204 - precision: 0.6689 - recall: 0.5049 - val_accuracy: 0.8126 - val_auc: 0.8530 - val_loss: 0.4227 - val_precision: 0.6730 - val_recall: 0.5684\n",
      "Epoch 34/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7988 - auc: 0.8524 - loss: 0.4234 - precision: 0.6638 - recall: 0.5219 - val_accuracy: 0.7999 - val_auc: 0.8513 - val_loss: 0.4252 - val_precision: 0.6492 - val_recall: 0.5308\n",
      "Epoch 35/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7950 - auc: 0.8502 - loss: 0.4300 - precision: 0.6713 - recall: 0.5027 - val_accuracy: 0.8098 - val_auc: 0.8506 - val_loss: 0.4253 - val_precision: 0.6792 - val_recall: 0.5335\n",
      "Epoch 36/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7971 - auc: 0.8474 - loss: 0.4285 - precision: 0.6620 - recall: 0.5030 - val_accuracy: 0.8055 - val_auc: 0.8527 - val_loss: 0.4232 - val_precision: 0.6749 - val_recall: 0.5121\n",
      "Epoch 37/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8158 - auc: 0.8571 - loss: 0.4095 - precision: 0.6789 - recall: 0.5297 - val_accuracy: 0.8084 - val_auc: 0.8535 - val_loss: 0.4222 - val_precision: 0.6594 - val_recall: 0.5710\n",
      "Epoch 38/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8087 - auc: 0.8533 - loss: 0.4214 - precision: 0.6749 - recall: 0.5377 - val_accuracy: 0.8055 - val_auc: 0.8503 - val_loss: 0.4251 - val_precision: 0.6787 - val_recall: 0.5040\n",
      "Epoch 39/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8071 - auc: 0.8525 - loss: 0.4205 - precision: 0.6744 - recall: 0.5112 - val_accuracy: 0.8155 - val_auc: 0.8535 - val_loss: 0.4242 - val_precision: 0.6707 - val_recall: 0.5952\n",
      "Epoch 40/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8077 - auc: 0.8588 - loss: 0.4191 - precision: 0.6850 - recall: 0.5592 - val_accuracy: 0.8006 - val_auc: 0.8523 - val_loss: 0.4234 - val_precision: 0.6679 - val_recall: 0.4906\n",
      "Epoch 41/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8106 - auc: 0.8569 - loss: 0.4148 - precision: 0.6901 - recall: 0.5075 - val_accuracy: 0.8155 - val_auc: 0.8527 - val_loss: 0.4229 - val_precision: 0.6805 - val_recall: 0.5710\n",
      "Epoch 42/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8109 - auc: 0.8571 - loss: 0.4124 - precision: 0.6762 - recall: 0.5288 - val_accuracy: 0.8155 - val_auc: 0.8531 - val_loss: 0.4241 - val_precision: 0.6749 - val_recall: 0.5845\n",
      "Epoch 43/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7965 - auc: 0.8492 - loss: 0.4296 - precision: 0.6578 - recall: 0.5302 - val_accuracy: 0.8141 - val_auc: 0.8505 - val_loss: 0.4256 - val_precision: 0.6729 - val_recall: 0.5791\n",
      "Epoch 44/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8121 - auc: 0.8546 - loss: 0.4199 - precision: 0.6804 - recall: 0.5551 - val_accuracy: 0.8162 - val_auc: 0.8532 - val_loss: 0.4218 - val_precision: 0.6839 - val_recall: 0.5684\n",
      "Epoch 45/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8029 - auc: 0.8438 - loss: 0.4222 - precision: 0.6561 - recall: 0.4787 - val_accuracy: 0.8133 - val_auc: 0.8536 - val_loss: 0.4212 - val_precision: 0.6719 - val_recall: 0.5764\n",
      "Epoch 46/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8174 - auc: 0.8610 - loss: 0.4105 - precision: 0.7001 - recall: 0.5467 - val_accuracy: 0.8148 - val_auc: 0.8513 - val_loss: 0.4259 - val_precision: 0.6867 - val_recall: 0.5523\n",
      "Epoch 47/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8070 - auc: 0.8516 - loss: 0.4202 - precision: 0.6874 - recall: 0.4996 - val_accuracy: 0.8062 - val_auc: 0.8477 - val_loss: 0.4280 - val_precision: 0.6852 - val_recall: 0.4960\n",
      "Epoch 48/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7995 - auc: 0.8521 - loss: 0.4266 - precision: 0.6863 - recall: 0.4795 - val_accuracy: 0.8141 - val_auc: 0.8504 - val_loss: 0.4254 - val_precision: 0.6762 - val_recall: 0.5710\n",
      "Epoch 49/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8054 - auc: 0.8596 - loss: 0.4095 - precision: 0.6715 - recall: 0.4971 - val_accuracy: 0.8162 - val_auc: 0.8515 - val_loss: 0.4254 - val_precision: 0.6759 - val_recall: 0.5871\n",
      "Epoch 50/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8100 - auc: 0.8555 - loss: 0.4094 - precision: 0.6530 - recall: 0.5161 - val_accuracy: 0.8105 - val_auc: 0.8537 - val_loss: 0.4247 - val_precision: 0.6532 - val_recall: 0.6059\n",
      "Epoch 51/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8062 - auc: 0.8664 - loss: 0.4056 - precision: 0.6637 - recall: 0.5535 - val_accuracy: 0.8091 - val_auc: 0.8500 - val_loss: 0.4272 - val_precision: 0.6667 - val_recall: 0.5576\n",
      "Epoch 52/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7952 - auc: 0.8473 - loss: 0.4276 - precision: 0.6506 - recall: 0.5013 - val_accuracy: 0.8141 - val_auc: 0.8510 - val_loss: 0.4252 - val_precision: 0.6975 - val_recall: 0.5255\n",
      "Epoch 53/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8111 - auc: 0.8561 - loss: 0.4128 - precision: 0.6791 - recall: 0.5259 - val_accuracy: 0.8070 - val_auc: 0.8507 - val_loss: 0.4281 - val_precision: 0.6563 - val_recall: 0.5684\n",
      "Epoch 54/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8065 - auc: 0.8551 - loss: 0.4156 - precision: 0.6713 - recall: 0.5183 - val_accuracy: 0.8077 - val_auc: 0.8481 - val_loss: 0.4296 - val_precision: 0.6723 - val_recall: 0.5335\n",
      "Epoch 55/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8024 - auc: 0.8609 - loss: 0.4092 - precision: 0.6591 - recall: 0.5084 - val_accuracy: 0.8034 - val_auc: 0.8480 - val_loss: 0.4296 - val_precision: 0.6548 - val_recall: 0.5442\n",
      "Epoch 56/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8188 - auc: 0.8595 - loss: 0.4082 - precision: 0.6956 - recall: 0.5279 - val_accuracy: 0.8155 - val_auc: 0.8506 - val_loss: 0.4263 - val_precision: 0.6667 - val_recall: 0.6059\n",
      "Epoch 57/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8001 - auc: 0.8472 - loss: 0.4258 - precision: 0.6655 - recall: 0.4972 - val_accuracy: 0.8062 - val_auc: 0.8469 - val_loss: 0.4294 - val_precision: 0.6667 - val_recall: 0.5362\n",
      "Epoch 58/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8197 - auc: 0.8656 - loss: 0.4089 - precision: 0.7127 - recall: 0.5578 - val_accuracy: 0.8070 - val_auc: 0.8461 - val_loss: 0.4323 - val_precision: 0.6563 - val_recall: 0.5684\n",
      "Epoch 59/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8029 - auc: 0.8483 - loss: 0.4219 - precision: 0.6607 - recall: 0.4992 - val_accuracy: 0.8084 - val_auc: 0.8489 - val_loss: 0.4318 - val_precision: 0.6585 - val_recall: 0.5737\n",
      "Epoch 60/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8160 - auc: 0.8649 - loss: 0.4084 - precision: 0.6964 - recall: 0.5508 - val_accuracy: 0.8070 - val_auc: 0.8487 - val_loss: 0.4274 - val_precision: 0.6554 - val_recall: 0.5710\n",
      "Epoch 61/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8055 - auc: 0.8546 - loss: 0.4158 - precision: 0.6602 - recall: 0.5333 - val_accuracy: 0.8055 - val_auc: 0.8500 - val_loss: 0.4252 - val_precision: 0.6523 - val_recall: 0.5684\n",
      "Epoch 62/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8218 - auc: 0.8649 - loss: 0.3999 - precision: 0.6981 - recall: 0.5339 - val_accuracy: 0.8055 - val_auc: 0.8503 - val_loss: 0.4277 - val_precision: 0.6394 - val_recall: 0.6086\n",
      "Epoch 63/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8012 - auc: 0.8581 - loss: 0.4156 - precision: 0.6589 - recall: 0.5455 - val_accuracy: 0.8034 - val_auc: 0.8465 - val_loss: 0.4295 - val_precision: 0.6600 - val_recall: 0.5308\n",
      "Epoch 64/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8166 - auc: 0.8707 - loss: 0.3974 - precision: 0.6916 - recall: 0.5264 - val_accuracy: 0.8126 - val_auc: 0.8487 - val_loss: 0.4276 - val_precision: 0.6741 - val_recall: 0.5657\n",
      "Epoch 65/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8169 - auc: 0.8628 - loss: 0.4058 - precision: 0.6886 - recall: 0.5537 - val_accuracy: 0.8077 - val_auc: 0.8498 - val_loss: 0.4250 - val_precision: 0.6645 - val_recall: 0.5523\n",
      "Epoch 65: early stopping\n",
      "Restoring model weights from the end of the best epoch: 45.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "### Neural Network Model Training\n",
    "\n",
    "This section defines and trains a neural network model using TensorFlow and Keras. The model is designed for binary classification, utilizing a fully connected architecture with regularization techniques to enhance generalization. Early stopping is employed to prevent overfitting by monitoring validation loss and restoring the best model weights.\n",
    "\"\"\"\n",
    "\n",
    "# Define the base neural network model\n",
    "base_model = Sequential([\n",
    "    Input(shape=(train_ds.element_spec[0].shape[1],)),  # Input layer with dynamic shape\n",
    "    Dense(50, activation='relu', kernel_regularizer=l2(0.001)),  # Hidden layer with L2 regularization\n",
    "    BatchNormalization(),  # Normalization to stabilize training\n",
    "    Dropout(0.5),  # Dropout to prevent overfitting\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Define the optimizer with a specific learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Compile the model with loss function and performance metrics\n",
    "base_model.compile(optimizer=optimizer,\n",
    "                   loss=\"binary_crossentropy\",\n",
    "                   metrics=[\"accuracy\", \"precision\", \"recall\", \"auc\"])\n",
    "\n",
    "# Define early stopping criteria to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss',  # Monitor validation loss\n",
    "                               patience=20,  # Stop if no improvement for 20 epochs\n",
    "                               verbose=1,  # Print messages when stopping\n",
    "                               restore_best_weights=True)  # Restore best weights\n",
    "\n",
    "# Train the model using the training dataset\n",
    "base_model_history = base_model.fit(train_ds,\n",
    "                                    epochs=1000,  # Maximum number of epochs\n",
    "                                    validation_data=val_ds,  # Validation dataset\n",
    "                                    verbose=1,  # Display training progress\n",
    "                                    callbacks=early_stopping)  # Apply early stopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1738833575405,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "Z9AYWNQFS6Iy",
    "outputId": "8908fc3b-9513-4354-b65d-b4b08d7d9da1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.7993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.8493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loss</td>\n",
       "      <td>0.4240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.6717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.4773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>val_accuracy</td>\n",
       "      <td>0.8133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>val_auc</td>\n",
       "      <td>0.8536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>val_loss</td>\n",
       "      <td>0.4212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>val_precision</td>\n",
       "      <td>0.6719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>val_recall</td>\n",
       "      <td>0.5764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>best_epoch</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Metric   Value\n",
       "0        accuracy  0.7993\n",
       "1             auc  0.8493\n",
       "2            loss  0.4240\n",
       "3       precision  0.6717\n",
       "4          recall  0.4773\n",
       "5    val_accuracy  0.8133\n",
       "6         val_auc  0.8536\n",
       "7        val_loss  0.4212\n",
       "8   val_precision  0.6719\n",
       "9      val_recall  0.5764\n",
       "10     best_epoch      45"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_epoch_details(base_model_history, metric=\"val_loss\", mode=min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123,
     "status": "ok",
     "timestamp": 1738833575530,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "8N-ItP93TAoW",
    "outputId": "e6fac651-a361-4196-d722-25ca8ca69d31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4211616814136505\n",
      "Validation Accuracy: 0.813342809677124\n",
      "Validation AUC: 0.8536428213119507\n",
      "Validation Precision: 0.671875\n",
      "Validation Recall: 0.5764074921607971\n",
      "Validation F1-Score: 0.6204906120651559\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy, val_precision, val_recall, val_auc = base_model.evaluate(val_ds, verbose=0)\n",
    "f1_score = 2 * (val_precision * val_recall) / (val_precision + val_recall)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation AUC: {val_auc}\")\n",
    "print(f\"Validation Precision: {val_precision}\")\n",
    "print(f\"Validation Recall: {val_recall}\")\n",
    "print(f\"Validation F1-Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_oEotBLXTMV_"
   },
   "source": [
    "# Weighted Cross-Entropy Loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07pMvIveTg2k"
   },
   "source": [
    "This is used to indicate that the classes are imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1738833575586,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "Y16M1ty-THbN",
    "outputId": "ef3329ff-6842-4b05-c26d-61a4ce6ada2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1869"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['Churn'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1738833575587,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "NUNDi6CeTlKS",
    "outputId": "d9d6d8c9-e6ce-4414-d927-6798c1eaef9b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5174"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['Churn'] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1738833575669,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "8019vLCfTpND"
   },
   "outputs": [],
   "source": [
    "class_weight_for_0 = 1.0 / len(df[df['Churn'] == 0])\n",
    "\n",
    "class_weight_for_1 = 1.0 / len(df[df['Churn'] == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h_j0xMfETxLD"
   },
   "source": [
    "We prevent the weights from being biased.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1738833575683,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "G6ULH4qWTqGE",
    "outputId": "70acc450-ed69-4865-835a-f9c0b6218e53"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00019327406262079628"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight_for_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1738833575684,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "KFR1KanTT034"
   },
   "outputs": [],
   "source": [
    "class_weights = {0: class_weight_for_0, 1: class_weight_for_1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44499,
     "status": "ok",
     "timestamp": 1738833620184,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "CkgENSl_T2uQ",
    "outputId": "69531006-4f0e-46e9-ef0e-86235ff8ccc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5825 - auc: 0.6135 - loss: 0.0318 - precision: 0.3287 - recall: 0.6073 - val_accuracy: 0.6977 - val_auc: 0.8149 - val_loss: 0.6492 - val_precision: 0.4630 - val_recall: 0.8901\n",
      "Epoch 2/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6802 - auc: 0.7701 - loss: 0.0024 - precision: 0.4460 - recall: 0.7639 - val_accuracy: 0.7779 - val_auc: 0.8475 - val_loss: 0.6011 - val_precision: 0.5595 - val_recall: 0.7560\n",
      "Epoch 3/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7173 - auc: 0.8097 - loss: 2.3848e-04 - precision: 0.4779 - recall: 0.7849 - val_accuracy: 0.7594 - val_auc: 0.8513 - val_loss: 0.5219 - val_precision: 0.5305 - val_recall: 0.7936\n",
      "Epoch 4/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7143 - auc: 0.8029 - loss: 1.6553e-04 - precision: 0.4736 - recall: 0.7708 - val_accuracy: 0.7509 - val_auc: 0.8382 - val_loss: 0.4965 - val_precision: 0.5195 - val_recall: 0.7855\n",
      "Epoch 5/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7213 - auc: 0.8079 - loss: 1.6144e-04 - precision: 0.4772 - recall: 0.7862 - val_accuracy: 0.7090 - val_auc: 0.8460 - val_loss: 0.5272 - val_precision: 0.4728 - val_recall: 0.8633\n",
      "Epoch 6/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7249 - auc: 0.8143 - loss: 1.6158e-04 - precision: 0.4927 - recall: 0.7823 - val_accuracy: 0.6934 - val_auc: 0.8464 - val_loss: 0.6036 - val_precision: 0.4589 - val_recall: 0.8820\n",
      "Epoch 7/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7273 - auc: 0.8123 - loss: 1.6187e-04 - precision: 0.4945 - recall: 0.7839 - val_accuracy: 0.7779 - val_auc: 0.8463 - val_loss: 0.4551 - val_precision: 0.5636 - val_recall: 0.7131\n",
      "Epoch 8/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7159 - auc: 0.8003 - loss: 1.6462e-04 - precision: 0.4617 - recall: 0.7661 - val_accuracy: 0.7779 - val_auc: 0.8561 - val_loss: 0.4602 - val_precision: 0.5558 - val_recall: 0.8016\n",
      "Epoch 9/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7385 - auc: 0.8294 - loss: 1.5676e-04 - precision: 0.5128 - recall: 0.8007 - val_accuracy: 0.7715 - val_auc: 0.8519 - val_loss: 0.4418 - val_precision: 0.5480 - val_recall: 0.7802\n",
      "Epoch 10/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7227 - auc: 0.8107 - loss: 1.6145e-04 - precision: 0.4767 - recall: 0.7977 - val_accuracy: 0.6806 - val_auc: 0.8538 - val_loss: 0.6080 - val_precision: 0.4483 - val_recall: 0.8954\n",
      "Epoch 11/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7241 - auc: 0.8008 - loss: 1.6588e-04 - precision: 0.4918 - recall: 0.7679 - val_accuracy: 0.7253 - val_auc: 0.8490 - val_loss: 0.5251 - val_precision: 0.4889 - val_recall: 0.8284\n",
      "Epoch 12/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7293 - auc: 0.8134 - loss: 1.6335e-04 - precision: 0.4966 - recall: 0.7865 - val_accuracy: 0.7260 - val_auc: 0.8476 - val_loss: 0.5146 - val_precision: 0.4900 - val_recall: 0.8579\n",
      "Epoch 13/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7195 - auc: 0.8045 - loss: 1.6413e-04 - precision: 0.4790 - recall: 0.7586 - val_accuracy: 0.7800 - val_auc: 0.8537 - val_loss: 0.4467 - val_precision: 0.5612 - val_recall: 0.7748\n",
      "Epoch 14/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7295 - auc: 0.8104 - loss: 1.6454e-04 - precision: 0.4973 - recall: 0.7860 - val_accuracy: 0.7509 - val_auc: 0.8448 - val_loss: 0.4937 - val_precision: 0.5189 - val_recall: 0.8097\n",
      "Epoch 15/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7243 - auc: 0.8045 - loss: 1.6807e-04 - precision: 0.4986 - recall: 0.7952 - val_accuracy: 0.7225 - val_auc: 0.8467 - val_loss: 0.5437 - val_precision: 0.4861 - val_recall: 0.8418\n",
      "Epoch 16/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7079 - auc: 0.8112 - loss: 1.6823e-04 - precision: 0.4765 - recall: 0.7990 - val_accuracy: 0.7573 - val_auc: 0.8446 - val_loss: 0.4815 - val_precision: 0.5279 - val_recall: 0.7855\n",
      "Epoch 17/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7327 - auc: 0.8142 - loss: 1.6208e-04 - precision: 0.5003 - recall: 0.7536 - val_accuracy: 0.7402 - val_auc: 0.8428 - val_loss: 0.4679 - val_precision: 0.5060 - val_recall: 0.7909\n",
      "Epoch 18/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7226 - auc: 0.8154 - loss: 1.6271e-04 - precision: 0.4902 - recall: 0.7879 - val_accuracy: 0.6877 - val_auc: 0.8530 - val_loss: 0.5765 - val_precision: 0.4552 - val_recall: 0.9115\n",
      "Epoch 19/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7197 - auc: 0.8114 - loss: 1.6210e-04 - precision: 0.4848 - recall: 0.7818 - val_accuracy: 0.6636 - val_auc: 0.8313 - val_loss: 0.6676 - val_precision: 0.4348 - val_recall: 0.9035\n",
      "Epoch 20/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7234 - auc: 0.8041 - loss: 1.6510e-04 - precision: 0.4847 - recall: 0.7670 - val_accuracy: 0.7821 - val_auc: 0.8512 - val_loss: 0.4394 - val_precision: 0.5660 - val_recall: 0.7587\n",
      "Epoch 21/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7209 - auc: 0.8049 - loss: 1.6387e-04 - precision: 0.4836 - recall: 0.7834 - val_accuracy: 0.7573 - val_auc: 0.8431 - val_loss: 0.5001 - val_precision: 0.5270 - val_recall: 0.8123\n",
      "Epoch 22/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7232 - auc: 0.8056 - loss: 1.6526e-04 - precision: 0.4833 - recall: 0.7580 - val_accuracy: 0.5607 - val_auc: 0.8067 - val_loss: 0.7733 - val_precision: 0.3689 - val_recall: 0.9276\n",
      "Epoch 23/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7043 - auc: 0.7930 - loss: 1.7035e-04 - precision: 0.4696 - recall: 0.7711 - val_accuracy: 0.7395 - val_auc: 0.8433 - val_loss: 0.5051 - val_precision: 0.5051 - val_recall: 0.8043\n",
      "Epoch 24/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7307 - auc: 0.8131 - loss: 1.6157e-04 - precision: 0.4913 - recall: 0.7790 - val_accuracy: 0.7111 - val_auc: 0.8459 - val_loss: 0.5332 - val_precision: 0.4745 - val_recall: 0.8472\n",
      "Epoch 25/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7052 - auc: 0.7954 - loss: 1.7106e-04 - precision: 0.4706 - recall: 0.7767 - val_accuracy: 0.6359 - val_auc: 0.8279 - val_loss: 0.6143 - val_precision: 0.4140 - val_recall: 0.9035\n",
      "Epoch 26/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7155 - auc: 0.7986 - loss: 1.6590e-04 - precision: 0.4761 - recall: 0.7588 - val_accuracy: 0.7402 - val_auc: 0.8426 - val_loss: 0.5005 - val_precision: 0.5058 - val_recall: 0.8123\n",
      "Epoch 27/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7211 - auc: 0.8108 - loss: 1.6236e-04 - precision: 0.4806 - recall: 0.7779 - val_accuracy: 0.7062 - val_auc: 0.8299 - val_loss: 0.5546 - val_precision: 0.4697 - val_recall: 0.8525\n",
      "Epoch 28/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7295 - auc: 0.8058 - loss: 1.6402e-04 - precision: 0.4865 - recall: 0.7735 - val_accuracy: 0.7438 - val_auc: 0.8505 - val_loss: 0.5031 - val_precision: 0.5102 - val_recall: 0.8016\n",
      "Epoch 29/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7252 - auc: 0.8130 - loss: 1.6169e-04 - precision: 0.4888 - recall: 0.7474 - val_accuracy: 0.7026 - val_auc: 0.8409 - val_loss: 0.5365 - val_precision: 0.4670 - val_recall: 0.8713\n",
      "Epoch 30/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7225 - auc: 0.8119 - loss: 1.6381e-04 - precision: 0.4877 - recall: 0.7941 - val_accuracy: 0.7040 - val_auc: 0.8490 - val_loss: 0.5548 - val_precision: 0.4688 - val_recall: 0.8847\n",
      "Epoch 31/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7178 - auc: 0.8071 - loss: 1.6283e-04 - precision: 0.4799 - recall: 0.7842 - val_accuracy: 0.7530 - val_auc: 0.8350 - val_loss: 0.4735 - val_precision: 0.5225 - val_recall: 0.7775\n",
      "Epoch 32/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7143 - auc: 0.8032 - loss: 1.6920e-04 - precision: 0.4779 - recall: 0.7977 - val_accuracy: 0.7722 - val_auc: 0.8400 - val_loss: 0.4530 - val_precision: 0.5533 - val_recall: 0.7239\n",
      "Epoch 33/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7266 - auc: 0.8189 - loss: 1.6084e-04 - precision: 0.4919 - recall: 0.7925 - val_accuracy: 0.7275 - val_auc: 0.8452 - val_loss: 0.5434 - val_precision: 0.4915 - val_recall: 0.8552\n",
      "Epoch 34/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7292 - auc: 0.8082 - loss: 1.6338e-04 - precision: 0.4906 - recall: 0.7699 - val_accuracy: 0.7310 - val_auc: 0.8419 - val_loss: 0.5092 - val_precision: 0.4951 - val_recall: 0.8177\n",
      "Epoch 35/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7286 - auc: 0.8114 - loss: 1.6330e-04 - precision: 0.4892 - recall: 0.7891 - val_accuracy: 0.7495 - val_auc: 0.8453 - val_loss: 0.4859 - val_precision: 0.5176 - val_recall: 0.7882\n",
      "Epoch 36/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7071 - auc: 0.7992 - loss: 1.6661e-04 - precision: 0.4738 - recall: 0.7582 - val_accuracy: 0.7495 - val_auc: 0.8516 - val_loss: 0.4952 - val_precision: 0.5167 - val_recall: 0.8311\n",
      "Epoch 37/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7192 - auc: 0.8030 - loss: 1.6512e-04 - precision: 0.4733 - recall: 0.7658 - val_accuracy: 0.7097 - val_auc: 0.8342 - val_loss: 0.5554 - val_precision: 0.4727 - val_recall: 0.8365\n",
      "Epoch 38/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7244 - auc: 0.8089 - loss: 1.6345e-04 - precision: 0.4869 - recall: 0.7817 - val_accuracy: 0.7587 - val_auc: 0.8552 - val_loss: 0.4737 - val_precision: 0.5291 - val_recall: 0.8043\n",
      "Epoch 39/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7159 - auc: 0.8010 - loss: 1.6598e-04 - precision: 0.4663 - recall: 0.7732 - val_accuracy: 0.6671 - val_auc: 0.8357 - val_loss: 0.5853 - val_precision: 0.4368 - val_recall: 0.8901\n",
      "Epoch 40/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7222 - auc: 0.8051 - loss: 1.6326e-04 - precision: 0.4743 - recall: 0.7706 - val_accuracy: 0.7523 - val_auc: 0.8531 - val_loss: 0.4826 - val_precision: 0.5205 - val_recall: 0.8150\n",
      "Epoch 40: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n"
     ]
    }
   ],
   "source": [
    "### Define the neural network model\n",
    "base_model = Sequential([\n",
    "    Input(shape=(train_ds.element_spec[0].shape[1],)),  # Input layer with dynamic shape\n",
    "    Dense(50, activation='relu', kernel_regularizer=l2(0.001)),  # Hidden layer with L2 regularization to prevent overfitting\n",
    "    BatchNormalization(),  # Normalization layer to stabilize training\n",
    "    Dropout(0.5),  # Dropout to reduce overfitting\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Define the optimizer with a specified learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "# Compile the model with loss function and evaluation metrics\n",
    "base_model.compile(optimizer=optimizer,\n",
    "                   loss=\"binary_crossentropy\",  # Loss function for binary classification\n",
    "                   metrics=[\"accuracy\", \"precision\", \"recall\", \"auc\"])  # Performance metrics\n",
    "\n",
    "# Define early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss',  # Monitor validation loss\n",
    "                               patience=20,  # Stop training if no improvement for 20 epochs\n",
    "                               verbose=1,  # Print messages when early stopping is triggered\n",
    "                               restore_best_weights=True,  # Restore the best model weights\n",
    "                               mode='min')  # Ensure the monitored value is minimized\n",
    "\n",
    "# Train the model with class weighting to handle imbalance\n",
    "base_model_history = base_model.fit(train_ds,\n",
    "                                    epochs=1000,  # Maximum number of epochs\n",
    "                                    validation_data=val_ds,  # Validation dataset\n",
    "                                    verbose=1,  # Display training progress\n",
    "                                    callbacks=early_stopping,  # Apply early stopping\n",
    "                                    class_weight=class_weights)  # Adjust training for imbalanced classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1738833620235,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "YcoHHJckV4Gt",
    "outputId": "2ecde6c5-52ff-409e-ea43-bf6982f88687"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.7238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.8050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loss</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.4874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.7781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>val_accuracy</td>\n",
       "      <td>0.7821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>val_auc</td>\n",
       "      <td>0.8512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>val_loss</td>\n",
       "      <td>0.4394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>val_precision</td>\n",
       "      <td>0.5660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>val_recall</td>\n",
       "      <td>0.7587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>best_epoch</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Metric   Value\n",
       "0        accuracy  0.7238\n",
       "1             auc  0.8050\n",
       "2            loss  0.0002\n",
       "3       precision  0.4874\n",
       "4          recall  0.7781\n",
       "5    val_accuracy  0.7821\n",
       "6         val_auc  0.8512\n",
       "7        val_loss  0.4394\n",
       "8   val_precision  0.5660\n",
       "9      val_recall  0.7587\n",
       "10     best_epoch      20"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_epoch_details(base_model_history, metric=\"val_loss\", mode=min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63,
     "status": "ok",
     "timestamp": 1738833620301,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "uIZZRjq6V7CB",
    "outputId": "6895f48c-f3d4-4496-fa3f-b040c24ee3b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4394136965274811\n",
      "Validation Accuracy: 0.7821149826049805\n",
      "Validation AUC: 0.8512362241744995\n",
      "Validation Precision: 0.5659999847412109\n",
      "Validation Recall: 0.7587131261825562\n",
      "Validation F1-Score: 0.6483390468489076\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy, val_precision, val_recall, val_auc = base_model.evaluate(val_ds, verbose=0)\n",
    "f1_score = 2 * (val_precision * val_recall) / (val_precision + val_recall)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation AUC: {val_auc}\")\n",
    "print(f\"Validation Precision: {val_precision}\")\n",
    "print(f\"Validation Recall: {val_recall}\")\n",
    "print(f\"Validation F1-Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGxJ04A_V_Bj"
   },
   "source": [
    "# Weighted Cross-Entropy Loss and Monitoring With AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28645,
     "status": "ok",
     "timestamp": 1738833648995,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "Yyq3zNjbWAKK",
    "outputId": "458f264c-2dc0-4a4c-a710-4f5ceb80f9f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5057 - auc: 0.5211 - loss: 0.0312 - precision: 0.2775 - recall: 0.5288 - val_accuracy: 0.6636 - val_auc: 0.7965 - val_loss: 0.6646 - val_precision: 0.4302 - val_recall: 0.8338\n",
      "Epoch 2/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6461 - auc: 0.7348 - loss: 0.0024 - precision: 0.4076 - recall: 0.7327 - val_accuracy: 0.7928 - val_auc: 0.8439 - val_loss: 0.5916 - val_precision: 0.5940 - val_recall: 0.6863\n",
      "Epoch 3/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7267 - auc: 0.8105 - loss: 2.3716e-04 - precision: 0.4896 - recall: 0.7820 - val_accuracy: 0.7999 - val_auc: 0.8503 - val_loss: 0.5287 - val_precision: 0.6022 - val_recall: 0.7185\n",
      "Epoch 4/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7144 - auc: 0.8017 - loss: 1.6788e-04 - precision: 0.4821 - recall: 0.7448 - val_accuracy: 0.7750 - val_auc: 0.8450 - val_loss: 0.4820 - val_precision: 0.5556 - val_recall: 0.7507\n",
      "Epoch 5/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7243 - auc: 0.8113 - loss: 1.6530e-04 - precision: 0.4968 - recall: 0.7856 - val_accuracy: 0.7431 - val_auc: 0.8394 - val_loss: 0.5065 - val_precision: 0.5094 - val_recall: 0.7989\n",
      "Epoch 6/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7323 - auc: 0.8209 - loss: 1.5899e-04 - precision: 0.4951 - recall: 0.7841 - val_accuracy: 0.7438 - val_auc: 0.8488 - val_loss: 0.4891 - val_precision: 0.5099 - val_recall: 0.8311\n",
      "Epoch 7/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7241 - auc: 0.8169 - loss: 1.5967e-04 - precision: 0.4809 - recall: 0.7944 - val_accuracy: 0.7175 - val_auc: 0.8475 - val_loss: 0.5451 - val_precision: 0.4810 - val_recall: 0.8499\n",
      "Epoch 8/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7186 - auc: 0.8126 - loss: 1.6251e-04 - precision: 0.4763 - recall: 0.7878 - val_accuracy: 0.7019 - val_auc: 0.8416 - val_loss: 0.5266 - val_precision: 0.4658 - val_recall: 0.8579\n",
      "Epoch 9/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7042 - auc: 0.8077 - loss: 1.6317e-04 - precision: 0.4662 - recall: 0.7868 - val_accuracy: 0.7296 - val_auc: 0.8401 - val_loss: 0.5249 - val_precision: 0.4936 - val_recall: 0.8284\n",
      "Epoch 10/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7238 - auc: 0.8058 - loss: 1.6638e-04 - precision: 0.4937 - recall: 0.7761 - val_accuracy: 0.6423 - val_auc: 0.8336 - val_loss: 0.6467 - val_precision: 0.4178 - val_recall: 0.8928\n",
      "Epoch 11/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7211 - auc: 0.8079 - loss: 1.6419e-04 - precision: 0.4790 - recall: 0.7773 - val_accuracy: 0.7899 - val_auc: 0.8533 - val_loss: 0.4262 - val_precision: 0.5842 - val_recall: 0.7158\n",
      "Epoch 12/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7160 - auc: 0.8055 - loss: 1.6544e-04 - precision: 0.4772 - recall: 0.7809 - val_accuracy: 0.7509 - val_auc: 0.8378 - val_loss: 0.4704 - val_precision: 0.5202 - val_recall: 0.7587\n",
      "Epoch 13/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7281 - auc: 0.8146 - loss: 1.6182e-04 - precision: 0.4973 - recall: 0.7829 - val_accuracy: 0.6487 - val_auc: 0.8407 - val_loss: 0.6843 - val_precision: 0.4238 - val_recall: 0.9088\n",
      "Epoch 14/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7018 - auc: 0.7889 - loss: 1.7052e-04 - precision: 0.4651 - recall: 0.7669 - val_accuracy: 0.7622 - val_auc: 0.8499 - val_loss: 0.4905 - val_precision: 0.5335 - val_recall: 0.8123\n",
      "Epoch 15/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7335 - auc: 0.8101 - loss: 1.6406e-04 - precision: 0.5007 - recall: 0.7613 - val_accuracy: 0.7452 - val_auc: 0.8417 - val_loss: 0.4935 - val_precision: 0.5123 - val_recall: 0.7828\n",
      "Epoch 16/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7174 - auc: 0.8045 - loss: 1.6381e-04 - precision: 0.4793 - recall: 0.7857 - val_accuracy: 0.7090 - val_auc: 0.8501 - val_loss: 0.5382 - val_precision: 0.4730 - val_recall: 0.8686\n",
      "Epoch 17/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7254 - auc: 0.8139 - loss: 1.6410e-04 - precision: 0.4986 - recall: 0.7860 - val_accuracy: 0.7722 - val_auc: 0.8493 - val_loss: 0.4513 - val_precision: 0.5504 - val_recall: 0.7614\n",
      "Epoch 18/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7181 - auc: 0.8105 - loss: 1.6521e-04 - precision: 0.4740 - recall: 0.7875 - val_accuracy: 0.7119 - val_auc: 0.8322 - val_loss: 0.5439 - val_precision: 0.4750 - val_recall: 0.8418\n",
      "Epoch 19/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7121 - auc: 0.7965 - loss: 1.6748e-04 - precision: 0.4714 - recall: 0.7545 - val_accuracy: 0.7303 - val_auc: 0.8418 - val_loss: 0.5094 - val_precision: 0.4944 - val_recall: 0.8284\n",
      "Epoch 20/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7224 - auc: 0.8127 - loss: 1.6427e-04 - precision: 0.4824 - recall: 0.7956 - val_accuracy: 0.6870 - val_auc: 0.8457 - val_loss: 0.6270 - val_precision: 0.4536 - val_recall: 0.8901\n",
      "Epoch 21/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7344 - auc: 0.8126 - loss: 1.6296e-04 - precision: 0.5015 - recall: 0.7683 - val_accuracy: 0.7346 - val_auc: 0.8509 - val_loss: 0.5006 - val_precision: 0.4992 - val_recall: 0.8257\n",
      "Epoch 22/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7208 - auc: 0.8052 - loss: 1.6261e-04 - precision: 0.4722 - recall: 0.7850 - val_accuracy: 0.6870 - val_auc: 0.8471 - val_loss: 0.6290 - val_precision: 0.4537 - val_recall: 0.8928\n",
      "Epoch 23/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7191 - auc: 0.7991 - loss: 1.7080e-04 - precision: 0.4879 - recall: 0.7843 - val_accuracy: 0.7317 - val_auc: 0.8360 - val_loss: 0.5035 - val_precision: 0.4959 - val_recall: 0.8016\n",
      "Epoch 24/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7282 - auc: 0.8136 - loss: 1.6330e-04 - precision: 0.4977 - recall: 0.7737 - val_accuracy: 0.7700 - val_auc: 0.8397 - val_loss: 0.4663 - val_precision: 0.5495 - val_recall: 0.7292\n",
      "Epoch 25/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7334 - auc: 0.8071 - loss: 1.6639e-04 - precision: 0.4928 - recall: 0.7983 - val_accuracy: 0.6544 - val_auc: 0.8252 - val_loss: 0.6510 - val_precision: 0.4256 - val_recall: 0.8740\n",
      "Epoch 26/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7124 - auc: 0.7920 - loss: 1.7505e-04 - precision: 0.4898 - recall: 0.7655 - val_accuracy: 0.7154 - val_auc: 0.8411 - val_loss: 0.5443 - val_precision: 0.4791 - val_recall: 0.8606\n",
      "Epoch 27/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7375 - auc: 0.8188 - loss: 1.6048e-04 - precision: 0.5089 - recall: 0.7913 - val_accuracy: 0.7608 - val_auc: 0.8298 - val_loss: 0.4910 - val_precision: 0.5344 - val_recall: 0.7507\n",
      "Epoch 28/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7304 - auc: 0.8136 - loss: 1.6230e-04 - precision: 0.4949 - recall: 0.7598 - val_accuracy: 0.7317 - val_auc: 0.8477 - val_loss: 0.5094 - val_precision: 0.4961 - val_recall: 0.8499\n",
      "Epoch 29/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7062 - auc: 0.7954 - loss: 1.7458e-04 - precision: 0.4761 - recall: 0.7741 - val_accuracy: 0.7076 - val_auc: 0.8499 - val_loss: 0.5361 - val_precision: 0.4714 - val_recall: 0.8633\n",
      "Epoch 30/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7222 - auc: 0.8073 - loss: 1.6237e-04 - precision: 0.4799 - recall: 0.7692 - val_accuracy: 0.7580 - val_auc: 0.8473 - val_loss: 0.4762 - val_precision: 0.5282 - val_recall: 0.8043\n",
      "Epoch 31/1000\n",
      "\u001b[1m177/177\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7398 - auc: 0.8173 - loss: 1.6198e-04 - precision: 0.5033 - recall: 0.7905 - val_accuracy: 0.7573 - val_auc: 0.8462 - val_loss: 0.4750 - val_precision: 0.5276 - val_recall: 0.7936\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 11.\n"
     ]
    }
   ],
   "source": [
    "class_weights = {0: class_weight_for_0, 1: class_weight_for_1}\n",
    "\n",
    "base_model = Sequential([\n",
    "    Input(shape=(train_ds.element_spec[0].shape[1],)),\n",
    "    Dense(50, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')])\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "\n",
    "base_model.compile(optimizer=optimizer,\n",
    "                   loss=\"binary_crossentropy\",\n",
    "                   metrics=[\"accuracy\", \"precision\", \"recall\", \"auc\"])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_auc', #*******\n",
    "                               patience=20,\n",
    "                               verbose=1,\n",
    "                               restore_best_weights=True,\n",
    "                               mode='max') #*******\n",
    "\n",
    "base_model_history = base_model.fit(train_ds,\n",
    "                                    epochs=1000,\n",
    "                                    validation_data=val_ds,\n",
    "                                    verbose=1,\n",
    "                                    callbacks=early_stopping,\n",
    "                                    class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 66,
     "status": "ok",
     "timestamp": 1738833649071,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "opGH_ARkWJoV",
    "outputId": "15bb0970-e12a-4748-9d4d-12d4b0d5b0d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.7226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.8109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loss</td>\n",
       "      <td>0.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.4859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.7734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>val_accuracy</td>\n",
       "      <td>0.7899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>val_auc</td>\n",
       "      <td>0.8533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>val_loss</td>\n",
       "      <td>0.4262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>val_precision</td>\n",
       "      <td>0.5842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>val_recall</td>\n",
       "      <td>0.7158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>best_epoch</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Metric   Value\n",
       "0        accuracy  0.7226\n",
       "1             auc  0.8109\n",
       "2            loss  0.0002\n",
       "3       precision  0.4859\n",
       "4          recall  0.7734\n",
       "5    val_accuracy  0.7899\n",
       "6         val_auc  0.8533\n",
       "7        val_loss  0.4262\n",
       "8   val_precision  0.5842\n",
       "9      val_recall  0.7158\n",
       "10     best_epoch      11"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_epoch_details(base_model_history, metric=\"val_auc\", mode=max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "ok",
     "timestamp": 1738833649142,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "XpobO9dXWMGx",
    "outputId": "a28a7d0d-27df-4a35-fd78-a56a8a504afe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.42617955803871155\n",
      "Validation Accuracy: 0.7899219393730164\n",
      "Validation AUC: 0.8533284068107605\n",
      "Validation Precision: 0.5842450857162476\n",
      "Validation Recall: 0.7158176898956299\n",
      "Validation F1-Score: 0.643373497704287\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy, val_precision, val_recall, val_auc = base_model.evaluate(val_ds, verbose=0)\n",
    "f1_score = 2 * (val_precision * val_recall) / (val_precision + val_recall)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation AUC: {val_auc}\")\n",
    "print(f\"Validation Precision: {val_precision}\")\n",
    "print(f\"Validation Recall: {val_recall}\")\n",
    "print(f\"Validation F1-Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2l97YnR3WOB_"
   },
   "source": [
    "# Hyperparameter Optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dltN2F4cWSAH"
   },
   "source": [
    "## Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1738833649191,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "Ea8xyRDqWP2n"
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    # Initialize a sequential model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(train_ds.element_spec[0].shape[1],)))\n",
    "\n",
    "    # Hidden layers with advanced activation functions, L2 regularization, and Dropout\n",
    "    for i in range(hp.Int('num_layers', 1, 10)):\n",
    "        # Add a Dense layer with tunable number of units and L2 regularization\n",
    "        model.add(Dense(\n",
    "            units=hp.Int('units_' + str(i + 1), min_value=32, max_value=512, step=16),\n",
    "            kernel_regularizer=l2(hp.Float('l2_' + str(i + 1), min_value=0.0001, max_value=0.01, sampling='log'))\n",
    "        ))\n",
    "\n",
    "        # Choose an activation function dynamically\n",
    "        activation_choice = hp.Choice('activation_' + str(i + 1), values=['relu', 'leaky_relu', 'prelu'])\n",
    "\n",
    "        if activation_choice == 'relu':\n",
    "            model.add(ReLU())  # ReLU activation function\n",
    "        elif activation_choice == 'leaky_relu':\n",
    "            model.add(LeakyReLU(negative_slope=0.01))  # Leaky ReLU to prevent dying neurons\n",
    "        elif activation_choice == 'prelu':\n",
    "            model.add(PReLU())  # Parametric ReLU for adaptive activation\n",
    "        else:\n",
    "            model.add(Activation(activation_choice))\n",
    "\n",
    "        # Add Batch Normalization for stabilizing training\n",
    "        model.add(BatchNormalization())\n",
    "\n",
    "        # Apply Dropout for regularization\n",
    "        model.add(Dropout(hp.Float('dropout_' + str(i + 1), min_value=0.0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    # Output layer with sigmoid activation for binary classification\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Configure the optimizer (Adam) with tunable beta parameters\n",
    "    optimizer = Adam(\n",
    "        beta_1=hp.Float('beta1', min_value=0.85, max_value=0.99, step=0.01),\n",
    "        beta_2=hp.Float('beta2', min_value=0.995, max_value=0.999, step=0.001)\n",
    "    )\n",
    "\n",
    "    # Compile the model with binary cross-entropy loss and key evaluation metrics\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\", \"precision\", \"recall\", \"auc\"])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDud1j5jWlVl"
   },
   "source": [
    "## Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2326094,
     "status": "ok",
     "timestamp": 1738835975255,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "QQVI1dtGWjW7",
    "outputId": "2887781a-ead4-4b34-eb0a-13ca226fc9cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 15s]\n",
      "val_loss: 0.4386385679244995\n",
      "\n",
      "Best val_loss So Far: 0.41866570711135864\n",
      "Total elapsed time: 00h 13m 01s\n"
     ]
    }
   ],
   "source": [
    "class_weights = {0: class_weight_for_0, 1: class_weight_for_1}\n",
    "\n",
    "random_search_tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=30,\n",
    "    executions_per_trial=1,\n",
    "    overwrite=True)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_auc',\n",
    "    patience=10,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    "    mode='max')\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'final_tuned_model.keras',\n",
    "    monitor='val_auc',\n",
    "    verbose=0,\n",
    "    save_best_only=True)\n",
    "\n",
    "random_search_tuner.search(train_ds,\n",
    "                           epochs=250,\n",
    "\n",
    "                           validation_data=val_ds,\n",
    "\n",
    "                           callbacks=[early_stopping, model_checkpoint],\n",
    "\n",
    "                           class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1738836103368,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "86nIvpR4Wn7_",
    "outputId": "b187efbe-2358-41f0-a59d-d651f47fe0ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Hyperparameter       Value\n",
      "0      num_layers           2\n",
      "1         units_1         288\n",
      "2            l2_1     0.00055\n",
      "3    activation_1       prelu\n",
      "4       dropout_1     0.10000\n",
      "5           beta1     0.94000\n",
      "6           beta2     0.99700\n",
      "7         units_2         480\n",
      "8            l2_2     0.00034\n",
      "9    activation_2       prelu\n",
      "10      dropout_2     0.40000\n",
      "11        units_3          64\n",
      "12           l2_3     0.00018\n",
      "13   activation_3       prelu\n",
      "14      dropout_3     0.00000\n",
      "15        units_4         128\n",
      "16           l2_4     0.00570\n",
      "17   activation_4        relu\n",
      "18      dropout_4     0.10000\n",
      "19        units_5         240\n",
      "20           l2_5     0.00040\n",
      "21   activation_5       prelu\n",
      "22      dropout_5     0.40000\n",
      "23        units_6         512\n",
      "24           l2_6     0.00019\n",
      "25   activation_6        relu\n",
      "26      dropout_6     0.40000\n",
      "27        units_7         464\n",
      "28           l2_7     0.00011\n",
      "29   activation_7       prelu\n",
      "30      dropout_7     0.10000\n",
      "31        units_8         400\n",
      "32           l2_8     0.00032\n",
      "33   activation_8        relu\n",
      "34      dropout_8     0.30000\n",
      "35        units_9         400\n",
      "36           l2_9     0.00120\n",
      "37   activation_9  leaky_relu\n",
      "38      dropout_9     0.10000\n",
      "39       units_10         336\n",
      "40          l2_10     0.00096\n",
      "41  activation_10        relu\n",
      "42     dropout_10     0.00000\n"
     ]
    }
   ],
   "source": [
    "best_hps = random_search_tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print_hyperparameters(best_hps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1738836105363,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "ShBJ1CVAW0HY",
    "outputId": "0c8d6e89-543f-4df2-af52-c864f658bb7f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_hps.joblib']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(best_hps, 'best_hps.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5835,
     "status": "ok",
     "timestamp": 1738836112655,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "Zo8l5KyzW2JK",
    "outputId": "5befa9d2-3a7c-4a09-929d-d2eef6138bb4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ahmet\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\saving\\saving_lib.py:757: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 26 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "best_model = random_search_tuner.get_best_models(num_models=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1738836112758,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "WHTTTT4gW2ip",
    "outputId": "ab9a39b1-ab66-4bce-b293-a10f2969db3a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,688</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">138,720</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">PReLU</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">480</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">481</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)            │        \u001b[38;5;34m14,688\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu (\u001b[38;5;33mPReLU\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)            │           \u001b[38;5;34m288\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)            │         \u001b[38;5;34m1,152\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)            │       \u001b[38;5;34m138,720\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ p_re_lu_1 (\u001b[38;5;33mPReLU\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)            │           \u001b[38;5;34m480\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)            │         \u001b[38;5;34m1,920\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m480\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m481\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">157,729</span> (616.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m157,729\u001b[0m (616.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">156,193</span> (610.13 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m156,193\u001b[0m (610.13 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2387,
     "status": "ok",
     "timestamp": 1738836115143,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "w0sSPJZPW36Q",
    "outputId": "4e1a4f84-858f-40fd-9355-d69d76639924"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.41866570711135864\n",
      "Validation Accuracy: 0.7977288961410522\n",
      "Validation AUC: 0.8529105186462402\n",
      "Validation Precision: 0.6042653918266296\n",
      "Validation Recall: 0.6836460828781128\n",
      "Validation F1-Score: 0.6415094146680984\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_accuracy, val_precision, val_recall, val_auc = best_model.evaluate(val_ds, verbose=0)\n",
    "f1_score = 2 * (val_precision * val_recall) / (val_precision + val_recall)\n",
    "print(f\"Validation Loss: {val_loss}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "print(f\"Validation AUC: {val_auc}\")\n",
    "print(f\"Validation Precision: {val_precision}\")\n",
    "print(f\"Validation Recall: {val_recall}\")\n",
    "print(f\"Validation F1-Score: {f1_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lK6gXvTGW-X6"
   },
   "source": [
    "# Retrain for Entire Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1738836115158,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "Iusm_O9zW912"
   },
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(train_ds.element_spec[0].shape[1],)))\n",
    "\n",
    "    # Hidden layers with advanced activation functions, l2, Dropout\n",
    "    for i in range(hp.Int('num_layers', 1, 10)):\n",
    "        # Add Dense layer\n",
    "        model.add(Dense(\n",
    "            units=hp.Int('units_' + str(i + 1), min_value=32, max_value=512, step=16),\n",
    "            kernel_regularizer=l2(hp.Float('l2_' + str(i + 1), min_value=0.0001, max_value=0.01, sampling='log'))\n",
    "        ))\n",
    "\n",
    "        # Activation layer choice\n",
    "        activation_choice = hp.Choice('activation_' + str(i + 1), values=['relu', 'leaky_relu', 'prelu'])\n",
    "\n",
    "        if activation_choice == 'relu':\n",
    "            model.add(ReLU())\n",
    "        elif activation_choice == 'leaky_relu':\n",
    "            model.add(LeakyReLU(negative_slope=0.01))\n",
    "        elif activation_choice == 'prelu':\n",
    "            model.add(PReLU())\n",
    "        else:\n",
    "            model.add(Activation(activation_choice))\n",
    "\n",
    "        # Batch Normalization and Dropout\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(hp.Float('dropout_' + str(i + 1), min_value=0.0, max_value=0.5, step=0.1)))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Optimizer: Adam with tuning for beta1 and beta2\n",
    "    optimizer = Adam(\n",
    "        beta_1=hp.Float('beta1', min_value=0.85, max_value=0.99, step=0.01),\n",
    "        beta_2=hp.Float('beta2', min_value=0.995, max_value=0.999, step=0.001)\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\", \"precision\", \"recall\", \"auc\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1738836115208,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "2PCbRSySXA48"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"churn.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1738836115505,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "7Nhr15IoXCQS"
   },
   "outputs": [],
   "source": [
    "X, y = dataproprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1738836115528,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "OgVtnv6vXDsq"
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X, y)).shuffle(buffer_size=len(X)).batch(len(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 459,
     "status": "ok",
     "timestamp": 1738836115988,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "ZNHNEnBbXFYj"
   },
   "outputs": [],
   "source": [
    "best_hps = load('best_hps.joblib')\n",
    "\n",
    "final_tuned_model = build_model(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 132515,
     "status": "ok",
     "timestamp": 1738836248510,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "cDVRfjwRXGtv",
    "outputId": "7f4cb746-ef6e-4f25-9dae-d4edad49db1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5207 - auc: 0.5367 - loss: 1.0921 - precision: 0.2851 - recall: 0.5350\n",
      "Epoch 2/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.6521 - auc: 0.7688 - loss: 0.9859 - precision: 0.4202 - recall: 0.8186\n",
      "Epoch 3/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.6760 - auc: 0.7998 - loss: 1.0180 - precision: 0.4416 - recall: 0.8357\n",
      "Epoch 4/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.6973 - auc: 0.8165 - loss: 0.9553 - precision: 0.4617 - recall: 0.8486\n",
      "Epoch 5/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.7000 - auc: 0.8123 - loss: 0.8857 - precision: 0.4632 - recall: 0.8208\n",
      "Epoch 6/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 0.6986 - auc: 0.7977 - loss: 0.8392 - precision: 0.4605 - recall: 0.7929\n",
      "Epoch 7/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 0.6739 - auc: 0.7578 - loss: 0.8359 - precision: 0.4328 - recall: 0.7373\n",
      "Epoch 8/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.6486 - auc: 0.7203 - loss: 0.8564 - precision: 0.4039 - recall: 0.6811\n",
      "Epoch 9/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step - accuracy: 0.6486 - auc: 0.7080 - loss: 0.8545 - precision: 0.4004 - recall: 0.6517\n",
      "Epoch 10/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.6716 - auc: 0.7389 - loss: 0.8161 - precision: 0.4260 - recall: 0.6838\n",
      "Epoch 11/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 0.7047 - auc: 0.7748 - loss: 0.7858 - precision: 0.4632 - recall: 0.7105\n",
      "Epoch 12/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.7183 - auc: 0.7977 - loss: 0.7714 - precision: 0.4798 - recall: 0.7309\n",
      "Epoch 13/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.7322 - auc: 0.8119 - loss: 0.7690 - precision: 0.4970 - recall: 0.7651\n",
      "Epoch 14/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.7397 - auc: 0.8216 - loss: 0.7680 - precision: 0.5064 - recall: 0.7657\n",
      "Epoch 15/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 146ms/step - accuracy: 0.7336 - auc: 0.8229 - loss: 0.7737 - precision: 0.4988 - recall: 0.7737\n",
      "Epoch 16/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.7449 - auc: 0.8292 - loss: 0.7599 - precision: 0.5127 - recall: 0.7796\n",
      "Epoch 17/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.7495 - auc: 0.8312 - loss: 0.7369 - precision: 0.5189 - recall: 0.7699\n",
      "Epoch 18/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.7437 - auc: 0.8232 - loss: 0.7395 - precision: 0.5116 - recall: 0.7539\n",
      "Epoch 19/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7502 - auc: 0.8261 - loss: 0.7094 - precision: 0.5204 - recall: 0.7496\n",
      "Epoch 20/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7430 - auc: 0.8140 - loss: 0.7152 - precision: 0.5110 - recall: 0.7341\n",
      "Epoch 21/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - accuracy: 0.7379 - auc: 0.8063 - loss: 0.7138 - precision: 0.5043 - recall: 0.7164\n",
      "Epoch 22/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7430 - auc: 0.8046 - loss: 0.6971 - precision: 0.5115 - recall: 0.7025\n",
      "Epoch 23/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 0.7413 - auc: 0.8065 - loss: 0.6920 - precision: 0.5092 - recall: 0.6972\n",
      "Epoch 24/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.7495 - auc: 0.8025 - loss: 0.6867 - precision: 0.5211 - recall: 0.6945\n",
      "Epoch 25/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.7518 - auc: 0.8060 - loss: 0.6810 - precision: 0.5244 - recall: 0.6950\n",
      "Epoch 26/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.7518 - auc: 0.8087 - loss: 0.6788 - precision: 0.5247 - recall: 0.6881\n",
      "Epoch 27/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 0.7626 - auc: 0.8211 - loss: 0.6655 - precision: 0.5401 - recall: 0.7100\n",
      "Epoch 28/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135ms/step - accuracy: 0.7637 - auc: 0.8232 - loss: 0.6674 - precision: 0.5414 - recall: 0.7164\n",
      "Epoch 29/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.7740 - auc: 0.8354 - loss: 0.6562 - precision: 0.5556 - recall: 0.7410\n",
      "Epoch 30/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.7748 - auc: 0.8375 - loss: 0.6524 - precision: 0.5570 - recall: 0.7400\n",
      "Epoch 31/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 0.7764 - auc: 0.8447 - loss: 0.6479 - precision: 0.5589 - recall: 0.7459\n",
      "Epoch 32/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.7788 - auc: 0.8440 - loss: 0.6478 - precision: 0.5630 - recall: 0.7437\n",
      "Epoch 33/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.7809 - auc: 0.8486 - loss: 0.6357 - precision: 0.5665 - recall: 0.7426\n",
      "Epoch 34/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 223ms/step - accuracy: 0.7830 - auc: 0.8478 - loss: 0.6326 - precision: 0.5703 - recall: 0.7405\n",
      "Epoch 35/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 0.7782 - auc: 0.8472 - loss: 0.6317 - precision: 0.5641 - recall: 0.7228\n",
      "Epoch 36/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.7901 - auc: 0.8471 - loss: 0.6237 - precision: 0.5856 - recall: 0.7154\n",
      "Epoch 37/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 209ms/step - accuracy: 0.7845 - auc: 0.8447 - loss: 0.6222 - precision: 0.5771 - recall: 0.7030\n",
      "Epoch 38/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.7904 - auc: 0.8455 - loss: 0.6163 - precision: 0.5886 - recall: 0.6988\n",
      "Epoch 39/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7924 - auc: 0.8418 - loss: 0.6150 - precision: 0.5935 - recall: 0.6913\n",
      "Epoch 40/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step - accuracy: 0.7909 - auc: 0.8459 - loss: 0.6074 - precision: 0.5917 - recall: 0.6838\n",
      "Epoch 41/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.7876 - auc: 0.8419 - loss: 0.6090 - precision: 0.5888 - recall: 0.6619\n",
      "Epoch 42/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.7906 - auc: 0.8406 - loss: 0.6068 - precision: 0.5939 - recall: 0.6667\n",
      "Epoch 43/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.7972 - auc: 0.8501 - loss: 0.5926 - precision: 0.6068 - recall: 0.6704\n",
      "Epoch 44/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.7999 - auc: 0.8460 - loss: 0.5991 - precision: 0.6120 - recall: 0.6726\n",
      "Epoch 45/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8011 - auc: 0.8560 - loss: 0.5853 - precision: 0.6090 - recall: 0.6993\n",
      "Epoch 46/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.7972 - auc: 0.8540 - loss: 0.5895 - precision: 0.6040 - recall: 0.6854\n",
      "Epoch 47/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.8005 - auc: 0.8570 - loss: 0.5868 - precision: 0.6091 - recall: 0.6929\n",
      "Epoch 48/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step - accuracy: 0.8099 - auc: 0.8616 - loss: 0.5804 - precision: 0.6268 - recall: 0.7009\n",
      "Epoch 49/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 148ms/step - accuracy: 0.8076 - auc: 0.8649 - loss: 0.5795 - precision: 0.6189 - recall: 0.7159\n",
      "Epoch 50/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.8073 - auc: 0.8677 - loss: 0.5710 - precision: 0.6210 - recall: 0.7030\n",
      "Epoch 51/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8174 - auc: 0.8691 - loss: 0.5679 - precision: 0.6401 - recall: 0.7127\n",
      "Epoch 52/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.8139 - auc: 0.8700 - loss: 0.5652 - precision: 0.6341 - recall: 0.7057\n",
      "Epoch 53/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182ms/step - accuracy: 0.8164 - auc: 0.8708 - loss: 0.5636 - precision: 0.6397 - recall: 0.7057\n",
      "Epoch 54/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 164ms/step - accuracy: 0.8185 - auc: 0.8705 - loss: 0.5589 - precision: 0.6468 - recall: 0.6966\n",
      "Epoch 55/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.8139 - auc: 0.8655 - loss: 0.5634 - precision: 0.6394 - recall: 0.6849\n",
      "Epoch 56/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.8140 - auc: 0.8692 - loss: 0.5587 - precision: 0.6411 - recall: 0.6795\n",
      "Epoch 57/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step - accuracy: 0.8134 - auc: 0.8684 - loss: 0.5552 - precision: 0.6427 - recall: 0.6688\n",
      "Epoch 58/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.8170 - auc: 0.8693 - loss: 0.5557 - precision: 0.6495 - recall: 0.6742\n",
      "Epoch 59/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174ms/step - accuracy: 0.8195 - auc: 0.8734 - loss: 0.5481 - precision: 0.6592 - recall: 0.6624\n",
      "Epoch 60/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.8275 - auc: 0.8810 - loss: 0.5374 - precision: 0.6665 - recall: 0.7004\n",
      "Epoch 61/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.8200 - auc: 0.8761 - loss: 0.5428 - precision: 0.6525 - recall: 0.6881\n",
      "Epoch 62/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.8225 - auc: 0.8803 - loss: 0.5356 - precision: 0.6613 - recall: 0.6790\n",
      "Epoch 63/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.8289 - auc: 0.8776 - loss: 0.5370 - precision: 0.6760 - recall: 0.6822\n",
      "Epoch 64/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8265 - auc: 0.8827 - loss: 0.5307 - precision: 0.6670 - recall: 0.6913\n",
      "Epoch 65/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.8266 - auc: 0.8796 - loss: 0.5315 - precision: 0.6680 - recall: 0.6891\n",
      "Epoch 66/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8256 - auc: 0.8841 - loss: 0.5284 - precision: 0.6665 - recall: 0.6865\n",
      "Epoch 67/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.8285 - auc: 0.8829 - loss: 0.5289 - precision: 0.6724 - recall: 0.6897\n",
      "Epoch 68/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8309 - auc: 0.8868 - loss: 0.5220 - precision: 0.6749 - recall: 0.6998\n",
      "Epoch 69/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.8300 - auc: 0.8854 - loss: 0.5231 - precision: 0.6768 - recall: 0.6881\n",
      "Epoch 70/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.8222 - auc: 0.8825 - loss: 0.5263 - precision: 0.6642 - recall: 0.6677\n",
      "Epoch 71/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8337 - auc: 0.8873 - loss: 0.5179 - precision: 0.6882 - recall: 0.6827\n",
      "Epoch 72/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 175ms/step - accuracy: 0.8325 - auc: 0.8910 - loss: 0.5117 - precision: 0.6890 - recall: 0.6720\n",
      "Epoch 73/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.8289 - auc: 0.8877 - loss: 0.5162 - precision: 0.6774 - recall: 0.6784\n",
      "Epoch 74/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.8320 - auc: 0.8910 - loss: 0.5127 - precision: 0.6874 - recall: 0.6731\n",
      "Epoch 75/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.8293 - auc: 0.8892 - loss: 0.5126 - precision: 0.6764 - recall: 0.6843\n",
      "Epoch 76/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - accuracy: 0.8302 - auc: 0.8885 - loss: 0.5126 - precision: 0.6818 - recall: 0.6752\n",
      "Epoch 77/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step - accuracy: 0.8413 - auc: 0.8940 - loss: 0.5032 - precision: 0.7022 - recall: 0.6977\n",
      "Epoch 78/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.8352 - auc: 0.8933 - loss: 0.5048 - precision: 0.6897 - recall: 0.6886\n",
      "Epoch 79/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.8414 - auc: 0.8965 - loss: 0.5003 - precision: 0.7028 - recall: 0.6972\n",
      "Epoch 80/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.8377 - auc: 0.8945 - loss: 0.5030 - precision: 0.6977 - recall: 0.6854\n",
      "Epoch 81/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.8367 - auc: 0.8949 - loss: 0.4993 - precision: 0.6963 - recall: 0.6822\n",
      "Epoch 82/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 0.8391 - auc: 0.8969 - loss: 0.4961 - precision: 0.7038 - recall: 0.6800\n",
      "Epoch 83/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8367 - auc: 0.8934 - loss: 0.5010 - precision: 0.6974 - recall: 0.6795\n",
      "Epoch 84/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.8417 - auc: 0.8978 - loss: 0.4923 - precision: 0.7113 - recall: 0.6790\n",
      "Epoch 85/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.8397 - auc: 0.8975 - loss: 0.4941 - precision: 0.7107 - recall: 0.6677\n",
      "Epoch 86/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.8464 - auc: 0.9041 - loss: 0.4835 - precision: 0.7190 - recall: 0.6913\n",
      "Epoch 87/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.8349 - auc: 0.8969 - loss: 0.4927 - precision: 0.6983 - recall: 0.6651\n",
      "Epoch 88/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 0.8489 - auc: 0.9030 - loss: 0.4820 - precision: 0.7275 - recall: 0.6886\n",
      "Epoch 89/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.8450 - auc: 0.9028 - loss: 0.4827 - precision: 0.7209 - recall: 0.6784\n",
      "Epoch 90/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.8477 - auc: 0.9029 - loss: 0.4810 - precision: 0.7251 - recall: 0.6859\n",
      "Epoch 91/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.8472 - auc: 0.9062 - loss: 0.4771 - precision: 0.7214 - recall: 0.6913\n",
      "Epoch 92/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 0.8462 - auc: 0.9077 - loss: 0.4745 - precision: 0.7191 - recall: 0.6902\n",
      "Epoch 93/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.8458 - auc: 0.9051 - loss: 0.4760 - precision: 0.7141 - recall: 0.6988\n",
      "Epoch 94/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 277ms/step - accuracy: 0.8459 - auc: 0.9084 - loss: 0.4732 - precision: 0.7207 - recall: 0.6849\n",
      "Epoch 95/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 0.8502 - auc: 0.9108 - loss: 0.4678 - precision: 0.7328 - recall: 0.6854\n",
      "Epoch 96/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 0.8508 - auc: 0.9147 - loss: 0.4616 - precision: 0.7275 - recall: 0.6998\n",
      "Epoch 97/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.8549 - auc: 0.9112 - loss: 0.4679 - precision: 0.7354 - recall: 0.7079\n",
      "Epoch 98/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 0.8513 - auc: 0.9135 - loss: 0.4605 - precision: 0.7368 - recall: 0.6843\n",
      "Epoch 99/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.8542 - auc: 0.9136 - loss: 0.4594 - precision: 0.7420 - recall: 0.6907\n",
      "Epoch 100/100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.8489 - auc: 0.9120 - loss: 0.4624 - precision: 0.7304 - recall: 0.6827\n",
      "Restoring model weights from the end of the best epoch: 99.\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True)\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'final_tuned_all_data_model.keras',\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True)\n",
    "\n",
    "final_history = final_tuned_model.fit(dataset,\n",
    "            epochs=100,\n",
    "            verbose=1,\n",
    "            callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1738836248589,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "sK7LwE0hXINT",
    "outputId": "08ebe9a8-92d8-416c-895f-76639369f712"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.8542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>auc</td>\n",
       "      <td>0.9136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>loss</td>\n",
       "      <td>0.4594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>precision</td>\n",
       "      <td>0.7420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recall</td>\n",
       "      <td>0.6907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>best_epoch</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Metric   Value\n",
       "0    accuracy  0.8542\n",
       "1         auc  0.9136\n",
       "2        loss  0.4594\n",
       "3   precision  0.7420\n",
       "4      recall  0.6907\n",
       "5  best_epoch      99"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_best_epoch_details(final_history, metric=\"loss\", mode=min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 148,
     "status": "ok",
     "timestamp": 1738836248736,
     "user": {
      "displayName": "Ahmet Yasir Duman",
      "userId": "07239445255758476458"
     },
     "user_tz": -180
    },
    "id": "xg_-yVQDXKh1"
   },
   "outputs": [],
   "source": [
    "final_tuned_model.save('final_tuned_all_data_model.keras')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPqggkXPVo516Fv29VF7pAm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
